{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'telecom.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(\"data/telecom.csv\")\n",
    "\n",
    "del df[\"customerID\"]\n",
    "df = df.replace({\"TotalCharges\": {\" \": 0},\n",
    "                \"Churn\": {\"Yes\": 1, \"No\": 0}})\n",
    "\n",
    "y = df[\"Churn\"]\n",
    "del df[\"Churn\"]\n",
    "\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], downcast=\"float\")\n",
    "\n",
    "df = df.replace({\"gender\": {\"Male\": 1, \"Female\": 0}, \n",
    "                \"Partner\": {\"Yes\": 1, \"No\": 0},\n",
    "                \"Dependents\": {\"Yes\": 1, \"No\": 0},\n",
    "                \"PhoneService\": {\"Yes\": 1, \"No\": 0},\n",
    "                \"MultipleLines\": {\"Yes\": 2, \"No\": 1, \"No phone service\": 0},\n",
    "                \"InternetService\": {\"Fiber optic\": 2, \"DSL\": 1, \"No\": 0},\n",
    "                \"OnlineSecurity\": {\"Yes\": 2, \"No\": 1, \"No internet service\": 0},\n",
    "                \"OnlineBackup\": {\"Yes\": 2, \"No\": 1, \"No internet service\": 0},\n",
    "                \"DeviceProtection\": {\"Yes\": 2, \"No\": 1, \"No internet service\": 0},\n",
    "                \"TechSupport\": {\"Yes\": 2, \"No\": 1, \"No internet service\": 0},\n",
    "                \"StreamingTV\": {\"Yes\": 2, \"No\": 1, \"No internet service\": 0},\n",
    "                \"StreamingMovies\": {\"Yes\": 2, \"No\": 1, \"No internet service\": 0},\n",
    "                \"Contract\": {\"Month-to-month\": 2, \"Two year\": 1, \"One year\": 0},\n",
    "                \"PaperlessBilling\": {\"Yes\": 1, \"No\": 0},\n",
    "                \"PaymentMethod\": {\"Electronic check\": 3, \"Mailed check\": 2, \"Credit card (automatic)\": 1, \"Bank transfer (automatic)\": 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>SeniorCitizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>PhoneService</th>\n      <th>MultipleLines</th>\n      <th>InternetService</th>\n      <th>OnlineSecurity</th>\n      <th>OnlineBackup</th>\n      <th>DeviceProtection</th>\n      <th>TechSupport</th>\n      <th>StreamingTV</th>\n      <th>StreamingMovies</th>\n      <th>Contract</th>\n      <th>PaperlessBilling</th>\n      <th>PaymentMethod</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>20.15</td>\n      <td>20.150000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>90.10</td>\n      <td>4549.450195</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>55</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>96.75</td>\n      <td>5238.899902</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>84.55</td>\n      <td>646.849976</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>79.75</td>\n      <td>159.399994</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5995</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>74.70</td>\n      <td>165.399994</td>\n    </tr>\n    <tr>\n      <th>5996</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>72</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>103.95</td>\n      <td>7517.700195</td>\n    </tr>\n    <tr>\n      <th>5997</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>64.95</td>\n      <td>493.649994</td>\n    </tr>\n    <tr>\n      <th>5998</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25.15</td>\n      <td>1940.849976</td>\n    </tr>\n    <tr>\n      <th>5999</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>66</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>110.60</td>\n      <td>7210.850098</td>\n    </tr>\n  </tbody>\n</table>\n<p>6000 rows Ã— 19 columns</p>\n</div>",
      "text/plain": "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n0          0              0        1           1       1             1   \n1          1              0        0           0      50             1   \n2          1              0        1           0      55             1   \n3          0              1        1           0       7             1   \n4          0              1        0           0       2             1   \n...      ...            ...      ...         ...     ...           ...   \n5995       1              1        0           0       2             1   \n5996       1              0        1           1      72             1   \n5997       0              1        0           0       7             1   \n5998       1              0        1           0      70             1   \n5999       0              1        1           1      66             1   \n\n      MultipleLines  InternetService  OnlineSecurity  OnlineBackup  \\\n0                 1                0               0             0   \n1                 1                2               2             2   \n2                 2                2               2             2   \n3                 2                2               1             1   \n4                 1                2               1             1   \n...             ...              ...             ...           ...   \n5995              1                2               1             2   \n5996              2                2               2             2   \n5997              1                1               1             2   \n5998              2                0               0             0   \n5999              2                2               2             2   \n\n      DeviceProtection  TechSupport  StreamingTV  StreamingMovies  Contract  \\\n0                    0            0            0                0         2   \n1                    2            2            1                1         0   \n2                    1            1            2                1         2   \n3                    1            1            1                2         2   \n4                    1            1            1                2         2   \n...                ...          ...          ...              ...       ...   \n5995                 1            1            1                1         2   \n5996                 2            2            1                2         1   \n5997                 2            1            2                1         2   \n5998                 0            0            0                0         1   \n5999                 1            2            2                2         0   \n\n      PaperlessBilling  PaymentMethod  MonthlyCharges  TotalCharges  \n0                    1              1           20.15     20.150000  \n1                    1              1           90.10   4549.450195  \n2                    1              3           96.75   5238.899902  \n3                    1              3           84.55    646.849976  \n4                    1              0           79.75    159.399994  \n...                ...            ...             ...           ...  \n5995                 1              3           74.70    165.399994  \n5996                 0              1          103.95   7517.700195  \n5997                 1              3           64.95    493.649994  \n5998                 0              0           25.15   1940.849976  \n5999                 1              1          110.60   7210.850098  \n\n[6000 rows x 19 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into 2 parts, take the small one as the final test. You will be using for each model's final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(df, y, test_size=1/6,random_state=109) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary for kepping the metrics from each model and the necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Logistic Regression\", \"Decision Tree\", \"SVM\", \"KNN\", \"Random Forest\", \"Ensemble Learning\", \"Neural Networks\"]\n",
    "coefs = dict()\n",
    "\n",
    "for model in models:\n",
    "    coefs[model] = {\n",
    "        \"Accuracy\": 0,\n",
    "        \"Precision\": 0,\n",
    "        \"Recall | Sensitivity\": 0,\n",
    "        \"Specificity\": 0,\n",
    "        \"Negative predictive value\": 0\n",
    "    }\n",
    "\n",
    "\n",
    "def perf_measure(y_actual, y_hat):   \n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(len(y_actual)):\n",
    "        if y_hat[i] == 1 and y_actual[i] == 1:\n",
    "            TP += 1\n",
    "        elif y_hat[i] == 1 and y_actual[i] == 0:\n",
    "            FP += 1\n",
    "        elif y_hat[i] == 0 and y_actual[i] == 0:\n",
    "            TN += 1\n",
    "        elif y_hat[i] == 0 and y_actual[i] == 1:\n",
    "            FN += 1\n",
    "        \n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "\n",
    "def return_metrics(tp, fp, tn, fn):\n",
    "    metrics = list()\n",
    "\n",
    "    metrics.append(round(((tp + tn) / (tp + tn + fp + fn)), 2))\n",
    "    metrics.append(round((tp / (tp + fp)), 2))\n",
    "    metrics.append(round((tp / (tp + fn)), 2))\n",
    "    metrics.append(round((tn / (tn + fp)), 2))\n",
    "    metrics.append(round((tn / (tn + fn)), 2))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def update_metrics(metrics, model):\n",
    "    coefs[model][\"Accuracy\"] = metrics[0]\n",
    "    coefs[model][\"Precision\"] = metrics[1]\n",
    "    coefs[model][\"Recall | Sensitivity\"] = metrics[2]\n",
    "    coefs[model][\"Specificity\"] = metrics[3]\n",
    "    coefs[model][\"Negative predictive value\"] = metrics[4]\n",
    "\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    print(\"Accuracy:\", metrics[0])\n",
    "    print(\"Precision:\", metrics[1])\n",
    "    print(\"Recall | Sensitivity:\", metrics[2])\n",
    "    print(\"Specificity:\", metrics[3])\n",
    "    print(\"Negative predictive value:\", metrics[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Precision: 0.68\n",
      "Recall | Sensitivity: 0.56\n",
      "Specificity: 0.9\n",
      "Negative predictive value: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(random_state=0, solver='newton-cg')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2,random_state=109) \n",
    "\n",
    "param_grid = {\"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "            \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "            \"multi_class\": [\"auto\", \"ovr\", \"multinomial\"]}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=0), param_grid, cv=6, n_jobs=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test.tolist(), y_pred.tolist())\n",
    "metrics = return_metrics(tp, fp, tn, fn)\n",
    "update_metrics(metrics, \"Logistic Regression\")\n",
    "print_metrics(metrics)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "Precision: 0.71\n",
      "Recall | Sensitivity: 0.43\n",
      "Specificity: 0.93\n",
      "Negative predictive value: 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2,random_state=109) \n",
    "\n",
    "param_grid = {\"max_depth\": range(3, 7),\n",
    "            \"min_samples_split\": range(2, 7),\n",
    "            \"min_samples_leaf\": range(1, 4),\n",
    "            \"max_features\": range(10, 15)}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=6, n_jobs=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test.tolist(), y_pred.tolist())\n",
    "metrics = return_metrics(tp, fp, tn, fn)\n",
    "update_metrics(metrics, \"Decision Tree\")\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n",
      "Precision: 0.23\n",
      "Recall | Sensitivity: 0.21\n",
      "Specificity: 0.73\n",
      "Negative predictive value: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2,random_state=109) \n",
    "\n",
    "param_grid = {\"kernel\": [\"sigmoid\"]}\n",
    "\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, cv=6, n_jobs=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test.tolist(), y_pred.tolist())\n",
    "metrics = return_metrics(tp, fp, tn, fn)\n",
    "update_metrics(metrics, \"SVM\")\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Precision: 0.68\n",
      "Recall | Sensitivity: 0.32\n",
      "Specificity: 0.94\n",
      "Negative predictive value: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=4)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2,random_state=109) \n",
    "\n",
    "param_grid = {\"n_neighbors\": range(3, 6),\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=6, n_jobs=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test.tolist(), y_pred.tolist())\n",
    "metrics = return_metrics(tp, fp, tn, fn)\n",
    "update_metrics(metrics, \"KNN\")\n",
    "print_metrics(metrics)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.73\n",
      "Recall | Sensitivity: 0.5\n",
      "Specificity: 0.93\n",
      "Negative predictive value: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2,random_state=109) \n",
    "\n",
    "param_grid = {\"n_estimators\": range(2, 20)}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=1), param_grid, cv=6, n_jobs=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test.tolist(), y_pred.tolist())\n",
    "metrics = return_metrics(tp, fp, tn, fn)\n",
    "update_metrics(metrics, \"Random Forest\")\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.71\n",
      "Recall | Sensitivity: 0.54\n",
      "Specificity: 0.91\n",
      "Negative predictive value: 0.84\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2,random_state=109) \n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=16, random_state=1)),\n",
    "    ('lr', LogisticRegression(random_state=0, solver='newton-cg'))\n",
    "]\n",
    "\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(random_state=0, solver='newton-cg')\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test.tolist(), y_pred.tolist())\n",
    "metrics = return_metrics(tp, fp, tn, fn)\n",
    "update_metrics(metrics, \"Ensemble Learning\")\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.5748 - accuracy: 0.7368\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7409\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7370\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7786\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7874\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7959\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7922\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8070\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8130\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8089\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7999\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8033\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8009\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8059\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8152\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.8043\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8030\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8065\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8117\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8168\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8055\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8034\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8112\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8117\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8059\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8197\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8135\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8098\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7963\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8033\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8180\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8251\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8062\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8050\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8142\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8046\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8033\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8037\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8065\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8037\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8092\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8113\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8139\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8067\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8195\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8156\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8159\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8091\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8110\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8103\n",
      "Accuracy: 0.81\n",
      "Precision: 0.84\n",
      "Recall | Sensitivity: 0.91\n",
      "Specificity: 0.55\n",
      "Negative predictive value: 0.7\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = train_X.iloc[:,:].values\n",
    "y = pd.DataFrame(train_y).iloc[:,:].values\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = OneHotEncoder().fit_transform(y).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=19, activation = \"sigmoid\"))\n",
    "model.add(Dense(12, activation=\"sigmoid\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64)\n",
    "\n",
    "y_pred = np.around(model.predict(X_test))\n",
    "\n",
    "def compiler(list):\n",
    "    if list[0] == 1 and list[1] == 0:\n",
    "        return 1\n",
    "    elif list[0] == 0 and list[1] == 1:\n",
    "        return 0\n",
    "    elif list[0] == list[1]:\n",
    "        return np.random.randint(0, 2)\n",
    "\n",
    "y_test = list(map(compiler, y_test))\n",
    "y_pred = list(map(compiler, y_pred))\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test, y_pred)\n",
    "metrics = return_metrics(tp, fp, tn, fn)\n",
    "update_metrics(metrics, \"Neural Networks\")\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The table of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall | Sensitivity</th>\n      <th>Specificity</th>\n      <th>Negative predictive value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.80</td>\n      <td>0.68</td>\n      <td>0.56</td>\n      <td>0.90</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>Decision Tree</th>\n      <td>0.79</td>\n      <td>0.71</td>\n      <td>0.43</td>\n      <td>0.93</td>\n      <td>0.81</td>\n    </tr>\n    <tr>\n      <th>SVM</th>\n      <td>0.59</td>\n      <td>0.23</td>\n      <td>0.21</td>\n      <td>0.73</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>KNN</th>\n      <td>0.77</td>\n      <td>0.68</td>\n      <td>0.32</td>\n      <td>0.94</td>\n      <td>0.78</td>\n    </tr>\n    <tr>\n      <th>Random Forest</th>\n      <td>0.81</td>\n      <td>0.73</td>\n      <td>0.50</td>\n      <td>0.93</td>\n      <td>0.83</td>\n    </tr>\n    <tr>\n      <th>Ensemble Learning</th>\n      <td>0.81</td>\n      <td>0.71</td>\n      <td>0.54</td>\n      <td>0.91</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>Neural Networks</th>\n      <td>0.81</td>\n      <td>0.84</td>\n      <td>0.91</td>\n      <td>0.55</td>\n      <td>0.70</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                     Accuracy  Precision  Recall | Sensitivity  Specificity  \\\nLogistic Regression      0.80       0.68                  0.56         0.90   \nDecision Tree            0.79       0.71                  0.43         0.93   \nSVM                      0.59       0.23                  0.21         0.73   \nKNN                      0.77       0.68                  0.32         0.94   \nRandom Forest            0.81       0.73                  0.50         0.93   \nEnsemble Learning        0.81       0.71                  0.54         0.91   \nNeural Networks          0.81       0.84                  0.91         0.55   \n\n                     Negative predictive value  \nLogistic Regression                       0.84  \nDecision Tree                             0.81  \nSVM                                       0.70  \nKNN                                       0.78  \nRandom Forest                             0.83  \nEnsemble Learning                         0.84  \nNeural Networks                           0.70  "
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(coefs).transpose()\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see Neural Networks give the best results in 3 most important metrics, so we will use them for our final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 0.5865 - accuracy: 0.7289\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7275\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7509\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7830\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8032\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8135\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7990\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8148\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8176\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8041\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8087\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8029\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8074\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8023\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8113\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8240\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8153\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8070\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8150\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7990\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8081\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8044\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8117\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8095\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.4106 - accuracy: 0.8102\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8104\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8040\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8191\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8101\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8048\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7974\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8138\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8064\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8008\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8045\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8156\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8096\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7972\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8145\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8121\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8034\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8078\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8054\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8105\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8056\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7993\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8086\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8206\n",
      "Epoch 50/50\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8212\n",
      "Accuracy: 0.8\n",
      "Precision: 0.86\n",
      "Recall | Sensitivity: 0.88\n",
      "Specificity: 0.56\n",
      "Negative predictive value: 0.6\n"
     ]
    }
   ],
   "source": [
    "X_train = train_X.iloc[:,:].values\n",
    "y_train = pd.DataFrame(train_y).iloc[:,:].values\n",
    "X_test = test_X.iloc[:,:].values\n",
    "y_test = pd.DataFrame(test_y).iloc[:,:].values\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "y_train = OneHotEncoder().fit_transform(y_train).toarray()\n",
    "y_test = OneHotEncoder().fit_transform(y_test).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=19, activation = \"sigmoid\"))\n",
    "model.add(Dense(12, activation=\"sigmoid\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64)\n",
    "\n",
    "y_pred = np.around(model.predict(X_test))\n",
    "\n",
    "def compiler(list):\n",
    "    if list[0] == 1 and list[1] == 0:\n",
    "        return 1\n",
    "    elif list[0] == 0 and list[1] == 1:\n",
    "        return 0\n",
    "    elif list[0] == list[1]:\n",
    "        return np.random.randint(0, 2)\n",
    "\n",
    "y_test = list(map(compiler, y_test))\n",
    "y_pred = list(map(compiler, y_pred))\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test, y_pred)\n",
    "metrics = return_metrics(tp, fp, tn, fn)\n",
    "print_metrics(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}